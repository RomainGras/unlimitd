{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e4cae02-5279-4859-861e-4009b73e381a",
   "metadata": {},
   "source": [
    "# 5-Layers Specialisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db1430e-20e9-4843-85e0-fcc62de75635",
   "metadata": {},
   "source": [
    "## 1st way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a99daa2-8c65-4b39-8daf-1a4177cadd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Original packages\n",
    "import backbone\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch.func import functional_call, vmap, vjp, jvp, jacrev\n",
    "from methods.meta_template import MetaTemplate\n",
    "import math\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR\n",
    "import warnings\n",
    "from torch.distributions import MultivariateNormal\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e513c76a-d060-4b59-8767-bdea0bbb5dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class simple_netC_0hl(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(simple_netC_0hl, self).__init__()\n",
    "        self.layer1 = nn.Linear(1600, 5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        return out\n",
    "\n",
    "net = simple_netC_0hl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b9a3df9-51bb-41c4-ac99-4aedd241c1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "c=0\n",
    "\n",
    "def compute_jacobian(inputs):   # i is the class label, and corresponds to the output targeted\n",
    "    \"\"\"\n",
    "    Return the jacobian of a batch of inputs, thanks to the vmap functionality\n",
    "    \"\"\"\n",
    "    net.zero_grad()\n",
    "    params = {k: v for k, v in net.named_parameters()}\n",
    "\n",
    "    def fnet_single(params, x):\n",
    "        # Make sure output has the right dimensions\n",
    "        return functional_call(net, params, (x.unsqueeze(0),)).squeeze(0)[c]\n",
    "\n",
    "    jac = vmap(jacrev(fnet_single), (None, 0))(params, inputs)\n",
    "    jac_values = jac.values()\n",
    "\n",
    "    reshaped_tensors = []\n",
    "    for j in jac_values:\n",
    "        if len(j.shape) == 3:  # For layers with weights\n",
    "            # Flatten parameters dimensions and then reshape\n",
    "            flattened = j.flatten(start_dim=1)  # Flattens to [batch, params]\n",
    "            reshaped = flattened.T  # Transpose to align dimensions as [params, batch]\n",
    "            reshaped_tensors.append(reshaped)\n",
    "        elif len(j.shape) == 2:  # For biases or single parameter components\n",
    "            reshaped_tensors.append(j.T)  # Simply transpose\n",
    "\n",
    "    # Concatenate all the reshaped tensors into one large matrix\n",
    "    return torch.cat(reshaped_tensors, dim=0).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf57e480-853b-4a5a-bb4c-6cb3f6d1c7e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [2., 2., 2.,  ..., 2., 2., 2.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(3, 1600)\n",
    "\n",
    "# Fill each row of the tensor with the row index\n",
    "for i in range(3):\n",
    "    x[i] = i\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e66696d8-5d4a-42a5-b77b-36fc3f5443fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "        [2., 2., 2.,  ..., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "print(compute_jacobian(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ac2c06f-7139-48b3-a097-119e7075feee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 5])\n",
      "tensor([[ 0.0078,  0.0053,  0.0200,  0.0206,  0.0170],\n",
      "        [ 0.5688,  0.2445,  0.5690, -0.3080,  0.3996],\n",
      "        [ 1.1297,  0.4838,  1.1180, -0.6366,  0.7822]])\n"
     ]
    }
   ],
   "source": [
    "# Constructing the specialisation matrix\n",
    "with torch.no_grad():\n",
    "    spe = net(x)\n",
    "print(spe.shape)\n",
    "print(spe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d52aad6e-13e7-434e-8fe2-e343a532ce0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0])\n"
     ]
    }
   ],
   "source": [
    "# Generate a single random number between 0 and n_classes\n",
    "random_class = torch.randint(low=0, high=5, size=(1,))\n",
    "\n",
    "print(random_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4ab98bb-6e4e-415a-943f-a1d521f841eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0078, 0.5688, 1.1297])\n"
     ]
    }
   ],
   "source": [
    "col = spe[:, random_class].flatten()\n",
    "print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c740376-ab7f-4261-bd28-1a1092b6920d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1717, 0.3009, 0.5273])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    softmax_col = F.softmax(col, dim=0)\n",
    "\n",
    "print(softmax_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1cdbb9c6-c511-455b-991e-f7789dffdab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2])\n"
     ]
    }
   ],
   "source": [
    "# Use multinomial to pick an index based on the weights\n",
    "# The second argument 'num_samples' is the number of indices to sample\n",
    "# 'replacement=True' allows picking the same index more than once if num_samples > 1\n",
    "random_index = torch.multinomial(softmax_col, num_samples=1, replacement=True)\n",
    "\n",
    "print(random_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e608c3af-f2f6-4a04-a632-2f83f249a8db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So input number 2 will have class number 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"So input number {random_index[0]} will have class number {random_class[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "daf83d70-19ae-45ef-b13f-a699ee966a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified Matrix:\n",
      " tensor([[ 0.0053,  0.0200,  0.0206,  0.0170],\n",
      "        [ 0.2445,  0.5690, -0.3080,  0.3996]])\n"
     ]
    }
   ],
   "source": [
    "#Now updating the matrix :\n",
    "i = random_index[0]\n",
    "j = random_class[0]\n",
    "# Remove the ith row\n",
    "new_spe = torch.cat((spe[:i], spe[i+1:]))\n",
    "\n",
    "# Remove the jth column\n",
    "new_spe = torch.cat((new_spe[:, :j], new_spe[:, j+1:]), dim=1)\n",
    "\n",
    "print(\"Modified Matrix:\\n\", new_spe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4fa50cf8-a3b6-43fe-bbaa-7d3c7430ac3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input number 2 will have class number 1\n",
      "Input number 4 will have class number 0\n",
      "Input number 3 will have class number 4\n",
      "Input number 1 will have class number 3\n",
      "Input number 0 will have class number 2\n"
     ]
    }
   ],
   "source": [
    "#repeat the process\n",
    "\n",
    "x = torch.empty(5, 1600)\n",
    "for i in range(5):\n",
    "    x[i] = i\n",
    "    \n",
    "# Constructing the specialisation matrix\n",
    "with torch.no_grad():\n",
    "    spe = net(x)\n",
    "\n",
    "classes = torch.tensor([0, 1, 2, 3, 4])\n",
    "for _ in range(5):\n",
    "    # Pick a class randomly with equal probability\n",
    "    random_class = classes[torch.randint(low=0, high=len(classes), size=(1,))]\n",
    "    col = spe[:, random_class].flatten()\n",
    "    with torch.no_grad():\n",
    "        softmax_col = F.softmax(col, dim=0)\n",
    "    random_index = torch.multinomial(softmax_col, num_samples=1, replacement=True)\n",
    "    \n",
    "    print(f\"Input number {random_index[0]} will have class number {random_class[0]}\")\n",
    "    \n",
    "    i = random_index[0]\n",
    "    j = random_class[0]\n",
    "    \n",
    "    # Remove the ith row\n",
    "    spe[i] = float('-inf')\n",
    "    \n",
    "    # can't pick the jth class anymore\n",
    "    mask = classes != random_class\n",
    "    classes = classes[mask]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c04965-a170-4970-a74f-b3d8071ed9f6",
   "metadata": {},
   "source": [
    "## 3rd option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4225d6f2-b734-42e8-a10b-266d55f44e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input number 3 will have class number 0\n",
      "Input number 1 will have class number 1\n",
      "Input number 4 will have class number 4\n",
      "Input number 2 will have class number 2\n",
      "Input number 0 will have class number 3\n"
     ]
    }
   ],
   "source": [
    "#repeat the process\n",
    "\n",
    "x = torch.empty(5, 1600)\n",
    "for i in range(5):\n",
    "    x[i] = i\n",
    "    \n",
    "# Constructing the specialisation matrix\n",
    "with torch.no_grad():\n",
    "    spe = net(x)\n",
    "\n",
    "flattened_spe = spe.flatten()\n",
    "for _ in range(5):\n",
    "    #Take the softmax of all the elements in the matrix\n",
    "    with torch.no_grad():\n",
    "        softmax_matrix = F.softmax(flattened_spe, dim=0)\n",
    "\n",
    "    rd_element_idx = torch.multinomial(softmax_matrix, num_samples=1, replacement=True)\n",
    "    rd_elemt = rd_element_idx // 5 # Indice of the row\n",
    "    rd_class = rd_element_idx % 5 # Indice of the column\n",
    "    indices_1 = torch.tensor([5 * i + rd_class for i in range(5)])\n",
    "    indices_2 = torch.tensor([i + rd_elemt * 5 for i in range(5)])\n",
    "\n",
    "    # Combine indices from both calculations, ensuring uniqueness if necessary\n",
    "    all_indices = torch.cat((indices_1, indices_2)).unique()\n",
    "    flattened_spe[all_indices] = float('-inf')\n",
    "    print(f\"Input number {rd_elemt[0]} will have class number {rd_class[0]}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18faf35f-7c78-452a-9116-618fb3796336",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
