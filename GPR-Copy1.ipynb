{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e82cf160-d685-4355-9bf2-044b3e7d8d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nll\n",
    "import numpy as np\n",
    "import utils\n",
    "from matplotlib import pyplot as plt\n",
    "import dataset_sines_infinite\n",
    "import dataset_sines_finite\n",
    "import dataset_step_infinite\n",
    "import scipy\n",
    "from scipy.special import gamma, kv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a6706391-9598-4182-92d2-4e2ddd8f3cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "seed = 2\n",
    "np.random.seed(seed)\n",
    "print(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "f68c9fbf-ca25-4567-8a7d-9e847d8bec22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_posterior_full(kernel_matrix, x_a, y_a, x_b, maddox_noise):\n",
    "    \"\"\"\n",
    "    Computes the gaussian posterior with this kernel and this data, on the queried inputs.\n",
    "    x_a is a (batch_size, input_dims) array (! has lost n_tasks)\n",
    "    y_a is a (batch_size, reg_dim) array (! has lost n_tasks)\n",
    "    Returns the posterior covariance matrix\n",
    "    \"\"\"\n",
    "    y_a = np.reshape(y_a, (-1,))\n",
    "\n",
    "    cov_a_a = kernel_matrix(x_a, x_a)\n",
    "    cov_a_a = cov_a_a + maddox_noise ** 2 * np.eye(cov_a_a.shape[0])\n",
    "    cov_b_a = kernel_matrix(x_b, x_a)\n",
    "    cov_b_b = kernel_matrix(x_b, x_b)\n",
    "\n",
    "    print(np.linalg.det(cov_a_a))\n",
    "    L = scipy.linalg.cho_factor(cov_a_a)\n",
    "    alpha = scipy.linalg.cho_solve(L, y_a)\n",
    "    post_mean = cov_b_a @ alpha\n",
    "    \n",
    "    v = scipy.linalg.cho_solve(L, cov_b_a.T)\n",
    "    post_cov = cov_b_b - cov_b_a @ v\n",
    "    \n",
    "    return post_mean, post_cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "df383f16-aff5-4c90-b2cb-8496d38c28d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_gpr(x_a_all, y_a_all, x_b, y_b, kernel_matrix, K, dataset_provider):\n",
    "    \"\"\"\n",
    "    Make an informative prediction plot in the singGP case (for the kernel specified)\n",
    "    K is the number of context inputs\n",
    "    Change dataset_provider to test on other datasets (e.g. dataset_sines_infinite)\n",
    "    \"\"\"\n",
    "    y_min, y_max = np.min(y_b) - 0.5, np.max(y_b) + 0.5\n",
    "\n",
    "    x_a = x_a_all[:K]\n",
    "    y_a = y_a_all[:K]\n",
    "    prediction, cov = gaussian_posterior_full(kernel_matrix, x_a, y_a, x_b, 0.05)\n",
    "\n",
    "    error = dataset_provider.error_fn(prediction, y_b)\n",
    "    loss = nll.nll(kernel_self_matrix, x_a, y_a, maddox_noise=0.05)\n",
    "\n",
    "    variances = np.diag(cov)\n",
    "    stds = np.sqrt(variances)\n",
    "\n",
    "    plt.plot(x_b, y_b, \"g--\", label=\"Target\")\n",
    "    plt.plot(x_a, y_a, \"ro\", label=\"Context data\")\n",
    "    plt.plot(x_b, prediction, \"b\", label=\"Prediction\")\n",
    "    plt.fill_between(x_b, prediction - 1.96 * stds, prediction + 1.96 * stds, color='blue', alpha=0.1, label=\"+/- 1.96$\\sigma$\")\n",
    "    plt.title(f\"NLL={loss:.4f}, MSE={error:.4f} ($K$={K})\")\n",
    "    plt.legend()\n",
    "    plt.gca().set_ylim([np.min(prediction), np.max(prediction)])\n",
    "    plt.gca().set_xlabel(\"$x$\")\n",
    "    plt.gca().set_ylabel(\"$y$\")\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5af5bf-a131-4bf2-8832-3d1a8f01a1e5",
   "metadata": {},
   "source": [
    "## Choice of kernels : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "bf849b91-0237-4928-b290-eb68347c40e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = 1\n",
    "\n",
    "def RBF_kernel(x1, x2):\n",
    "    # Now x1 and x2 are compatible for broadcasting\n",
    "    # Compute squared Euclidean distance\n",
    "    squared_diff = (x1 - x2) ** 2 / (2*l**2)\n",
    "    return np.exp(-np.sum((x1 - x2)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ffd83707-021b-4138-b3f7-62ee8b93f0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CosSim_kernel(x1, x2):\n",
    "    normalized_factor = np.linalg.norm(x1)*np.linalg.norm(x2)\n",
    "    return np.dot(x1, x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "55ab77a4-0845-44f4-9b1b-1aeefede2be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 2\n",
    "c = 1\n",
    "\n",
    "def polynomial_kernel(x1, x2):\n",
    "    return (np.dot(x1, x2) + c)**p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "6948a007-013e-499c-bacd-333ed027dde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "length_scale = 1\n",
    "nu = 2.5\n",
    "sigma = 1\n",
    "\n",
    "def matern_kernel(x1, x2):\n",
    "    \"\"\"\n",
    "    Compute the Mat√©rn kernel between points in x.\n",
    "\n",
    "    Parameters:\n",
    "    - x: array-like of shape (n_samples, n_features)\n",
    "    - length_scale: the length scale of the kernel.\n",
    "    - nu: smoothness parameter.\n",
    "    - sigma: variance parameter.\n",
    "\n",
    "    Returns:\n",
    "    - Kernel matrix of shape (n_samples, n_samples).\n",
    "    \"\"\"\n",
    "    # Compute pairwise Euclidean distances\n",
    "    pairwise_sq_dists = np.sum((x1 - x2)**2)\n",
    "    # Scale the distances by the length scale\n",
    "    sqrt_2_nu_d = np.sqrt(2 * nu * pairwise_sq_dists) / length_scale\n",
    "    # Compute the kernel\n",
    "    kernel = (sigma**2) * (2**(1-nu) / gamma(nu)) * (sqrt_2_nu_d**nu) * kv(nu, sqrt_2_nu_d)\n",
    "    # Handle zero distances (diagonal should be 1)\n",
    "    return kernel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ee15bb49-afde-4d1b-b1e5-363f062b5166",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = 4\n",
    "weights = np.array([1, 1, 1, 1])\n",
    "means = np.array([1, 1, 1, 1])\n",
    "variances = np.array([.1, .1, .1, .1])\n",
    "\n",
    "def spectral_mixture_kernel(x1, x2):\n",
    "    \"\"\"\n",
    "    Compute the Spectral Mixture (SM) kernel between arrays x and xp.\n",
    "\n",
    "    Parameters:\n",
    "    - x, xp: Arrays of shape (n_samples, 1) or similar (input points for the kernel).\n",
    "    - weights: Array of shape (Q,) where Q is the number of mixture components (mixture weights).\n",
    "    - means: Array of shape (Q,) (mean frequencies of the components).\n",
    "    - variances: Array of shape (Q,) (variances of the components).\n",
    "    - Q: int, number of spectral mixture components.\n",
    "\n",
    "    Returns:\n",
    "    - Kernel matrix of shape (n_samples_x, n_samples_xp).\n",
    "    \"\"\"\n",
    "    # Reshape to make broadcasting work correctly\n",
    "    # x = x[:, np.newaxis]  # Shape (n_samples_x, 1, 1)\n",
    "    # xp = xp[np.newaxis, :]  # Shape (1, n_samples_xp, 1)\n",
    "    \n",
    "    # Difference matrix\n",
    "    # r = x - xp  # Shape (n_samples_x, n_samples_xp, 1)\n",
    "    \n",
    "    # Initialize the kernel matrix\n",
    "    # kernel = np.zeros((x.shape[0], xp.shape[1]))\n",
    "    \n",
    "    # Sum over all mixture components\n",
    "    kernel = 0\n",
    "    for q in range(Q):\n",
    "        # Squared exponential decay term\n",
    "        exp_decay = np.exp(-2 * np.pi**2 * variances[q] * np.sum((x1 - x2)**2))\n",
    "        \n",
    "        # Cosine term\n",
    "        cos_term = np.cos(2 * np.pi * means[q] * np.sum((x1 - x2)**2))\n",
    "        \n",
    "        # Combine terms and add to the kernel matrix\n",
    "        kernel += weights[q] * exp_decay * cos_term\n",
    "    \n",
    "    return kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "6e4f5d4d-114b-4bdc-8f73-ffe763e0ccd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.00000000e+00 5.55644533e-01 1.48938922e-03 7.70359562e-08]\n",
      " [5.55644533e-01 4.00000000e+00 5.55644533e-01 1.48938922e-03]\n",
      " [1.48938922e-03 5.55644533e-01 4.00000000e+00 5.55644533e-01]]\n",
      "\n",
      "[[4.00000000e+00 5.55644533e-01 1.48938922e-03]\n",
      " [5.55644533e-01 4.00000000e+00 5.55644533e-01]\n",
      " [1.48938922e-03 5.55644533e-01 4.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "#Choose here: \n",
    "kernel = spectral_mixture_kernel\n",
    "vectorized_kernel = np.vectorize(kernel)\n",
    "\n",
    "def kernel_matrix(x1, x2):\n",
    "    matrix = vectorized_kernel(x1[:, np.newaxis], x2[np.newaxis, :])\n",
    "    # For matern_kernel\n",
    "    # matrix[np.isnan(matrix)] = sigma**2\n",
    "    return matrix\n",
    "\n",
    "def kernel_self_matrix(x1):\n",
    "    matrix = vectorized_kernel(x1[:, np.newaxis], x1[np.newaxis, :])\n",
    "    # For matern_kernel\n",
    "    # matrix[np.isnan(matrix)] = sigma**2\n",
    "    return matrix\n",
    "\n",
    "x = np.array([1, 2, 3])  # Vector of length k\n",
    "y = np.array([1, 2, 3, 4])  # Vector of length l.\n",
    "\n",
    "print(kernel_matrix(x, y))\n",
    "print()\n",
    "print(kernel_self_matrix(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd7d002-c3f1-47e3-8761-cac0bb6b69e7",
   "metadata": {},
   "source": [
    "## Get batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "bfa01f10-2113-4e97-8132-e8818400af38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fancy_test_batch(K, L, data_noise):\n",
    "    reg_dim = 1\n",
    "\n",
    "    function = draw_multi(reg_dim)\n",
    "    \n",
    "    x = np.random.uniform(low=-5, high=5, size=(K+L, 1))\n",
    "    y = function(x)\n",
    "    noise = np.random.normal(size=(K, reg_dim)) * data_noise\n",
    "    y[:K, :] = function(x[:K]) + noise\n",
    "    y[K:, :] = function(x[K:])\n",
    "\n",
    "    return x, y, function\n",
    "\n",
    "\n",
    "def draw_multi(reg_dim, amp_low=0.1, amp_high=5, phase_low=0, phase_high=np.pi):\n",
    "\n",
    "    amps = np.random.uniform(low=amp_low, high=amp_high, size=(reg_dim,))\n",
    "    phases = np.random.uniform(low=amp_low, high=amp_high, size=(reg_dim,))\n",
    "    \n",
    "    def function(x):\n",
    "        return amps * np.sin(x + phases) + 1\n",
    "        \n",
    "    return function\n",
    "\n",
    "# x, y, fun = get_fancy_test_batch(50, 0, 0.05)\n",
    "# x_fun = np.linspace(-5, 5, 100)\n",
    "# plt.plot(x, y, \"ro\")\n",
    "# plt.plot(x_fun, fun(x_fun))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "0a2f48e5-7f4b-40d2-87a6-be0373246605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-7.050812379342542\n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "7-th leading minor of the array is not positive definite",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[128], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m y_b \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mreshape(y_b, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,))\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# print(x_b.shape, y_b.shape)\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[43mplot_gpr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_a_all\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_a_all\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_b\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_b\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_sines_infinite\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[114], line 11\u001b[0m, in \u001b[0;36mplot_gpr\u001b[0;34m(x_a_all, y_a_all, x_b, y_b, kernel_matrix, K, dataset_provider)\u001b[0m\n\u001b[1;32m      9\u001b[0m x_a \u001b[38;5;241m=\u001b[39m x_a_all[:K]\n\u001b[1;32m     10\u001b[0m y_a \u001b[38;5;241m=\u001b[39m y_a_all[:K]\n\u001b[0;32m---> 11\u001b[0m prediction, cov \u001b[38;5;241m=\u001b[39m \u001b[43mgaussian_posterior_full\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkernel_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_b\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.05\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m error \u001b[38;5;241m=\u001b[39m dataset_provider\u001b[38;5;241m.\u001b[39merror_fn(prediction, y_b)\n\u001b[1;32m     14\u001b[0m loss \u001b[38;5;241m=\u001b[39m nll\u001b[38;5;241m.\u001b[39mnll(kernel_self_matrix, x_a, y_a, maddox_noise\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.05\u001b[39m)\n",
      "Cell \u001b[0;32mIn[127], line 16\u001b[0m, in \u001b[0;36mgaussian_posterior_full\u001b[0;34m(kernel_matrix, x_a, y_a, x_b, maddox_noise)\u001b[0m\n\u001b[1;32m     13\u001b[0m cov_b_b \u001b[38;5;241m=\u001b[39m kernel_matrix(x_b, x_b)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mdet(cov_a_a))\n\u001b[0;32m---> 16\u001b[0m L \u001b[38;5;241m=\u001b[39m \u001b[43mscipy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcho_factor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcov_a_a\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m alpha \u001b[38;5;241m=\u001b[39m scipy\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mcho_solve(L, y_a)\n\u001b[1;32m     18\u001b[0m post_mean \u001b[38;5;241m=\u001b[39m cov_b_a \u001b[38;5;241m@\u001b[39m alpha\n",
      "File \u001b[0;32m/state/partition1/llgrid/pkg/anaconda/python-LLM-2023b/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py:154\u001b[0m, in \u001b[0;36mcho_factor\u001b[0;34m(a, lower, overwrite_a, check_finite)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcho_factor\u001b[39m(a, lower\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, overwrite_a\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, check_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m     95\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;124;03m    Compute the Cholesky decomposition of a matrix, to use in cho_solve\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    152\u001b[0m \n\u001b[1;32m    153\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 154\u001b[0m     c, lower \u001b[38;5;241m=\u001b[39m \u001b[43m_cholesky\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlower\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite_a\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite_a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclean\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mcheck_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_finite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m c, lower\n",
      "File \u001b[0;32m/state/partition1/llgrid/pkg/anaconda/python-LLM-2023b/lib/python3.10/site-packages/scipy/linalg/_decomp_cholesky.py:37\u001b[0m, in \u001b[0;36m_cholesky\u001b[0;34m(a, lower, overwrite_a, clean, check_finite)\u001b[0m\n\u001b[1;32m     35\u001b[0m c, info \u001b[38;5;241m=\u001b[39m potrf(a1, lower\u001b[38;5;241m=\u001b[39mlower, overwrite_a\u001b[38;5;241m=\u001b[39moverwrite_a, clean\u001b[38;5;241m=\u001b[39mclean)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m info \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 37\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LinAlgError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m-th leading minor of the array is not positive \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     38\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefinite\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m info)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m info \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLAPACK reported an illegal value in \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m-th argument\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     41\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mon entry to \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPOTRF\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;241m-\u001b[39minfo))\n",
      "\u001b[0;31mLinAlgError\u001b[0m: 7-th leading minor of the array is not positive definite"
     ]
    }
   ],
   "source": [
    "K = 10\n",
    "x, y, fun = get_fancy_test_batch(K=K, L=0, data_noise=0.05)\n",
    "\n",
    "x_a_all = x[:K]\n",
    "y_a_all = y[:K]\n",
    "x_a_all = np.reshape(x_a_all, (-1,))\n",
    "y_a_all = np.reshape(y_a_all, (-1,))\n",
    "# print(x_a_all.shape, y_a_all.shape)\n",
    "\n",
    "x_b = np.linspace(-5, 5, 100)[:, np.newaxis]\n",
    "y_b = fun(x_b)\n",
    "x_b = np.reshape(x_b, (-1,))\n",
    "y_b = np.reshape(y_b, (-1,))\n",
    "# print(x_b.shape, y_b.shape)\n",
    "\n",
    "plot_gpr(x_a_all, y_a_all, x_b, y_b, kernel_matrix, K, dataset_sines_infinite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3953f2-4960-41cd-aa39-e2e4bf4a7e74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97d8a16-bf3c-408c-a8d3-87feca527f64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
